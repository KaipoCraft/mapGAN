{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9e9196",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KaipoCraft/mapGAN/blob/main/main2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482554cd-1e15-4430-9017-b0905f328aae",
   "metadata": {
    "id": "482554cd-1e15-4430-9017-b0905f328aae"
   },
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb10ce-a0e2-4581-a4ee-7e2be8b4b5e0",
   "metadata": {
    "id": "13fb10ce-a0e2-4581-a4ee-7e2be8b4b5e0",
    "tags": []
   },
   "source": [
    "Install & import Google Earth Engine's API, which we'll use to call the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d5d9c-0678-43e2-a7e4-f2e66a50e58e",
   "metadata": {
    "id": "f37d5d9c-0678-43e2-a7e4-f2e66a50e58e",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gm.update_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b011609-ee6a-4cf3-a17d-1b3ff109f459",
   "metadata": {
    "id": "2b011609-ee6a-4cf3-a17d-1b3ff109f459",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install earthengine-api --upgrade\n",
    "#!pip install geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d48dcd-8776-461a-a1be-cc79caaab6d5",
   "metadata": {
    "id": "f3d48dcd-8776-461a-a1be-cc79caaab6d5"
   },
   "outputs": [],
   "source": [
    "#import ee\n",
    "#import geemap as gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232ed5a-9c3b-4aa8-af1e-d333c4d98506",
   "metadata": {
    "id": "9232ed5a-9c3b-4aa8-af1e-d333c4d98506"
   },
   "outputs": [],
   "source": [
    "# Map = gm.Map()\n",
    "# Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785cda4-edd9-43b2-b0db-fb392343958b",
   "metadata": {
    "id": "0785cda4-edd9-43b2-b0db-fb392343958b"
   },
   "source": [
    "Basic ML packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c9ae12-df7b-4e77-a689-5766eddc5785",
   "metadata": {
    "id": "d8c9ae12-df7b-4e77-a689-5766eddc5785"
   },
   "outputs": [],
   "source": [
    "# import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc98629-7dfe-4442-9a65-a75c47c45253",
   "metadata": {
    "id": "cfc98629-7dfe-4442-9a65-a75c47c45253"
   },
   "source": [
    "Visualization packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2bedca-e884-4e5f-90be-756d8cc1b548",
   "metadata": {
    "id": "de2bedca-e884-4e5f-90be-756d8cc1b548"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763d27e-1831-4d14-8f6b-ff763c55fb53",
   "metadata": {
    "id": "6763d27e-1831-4d14-8f6b-ff763c55fb53"
   },
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedae47c-1584-4ad6-bf45-9e976e2ab9cb",
   "metadata": {
    "id": "cedae47c-1584-4ad6-bf45-9e976e2ab9cb"
   },
   "outputs": [],
   "source": [
    "#this version allows for GPU use\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5281279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see if Jupyter is registering a local GPU\n",
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40e131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551e0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd312de-9040-484c-8f10-b3402f1df06a",
   "metadata": {
    "id": "cfd312de-9040-484c-8f10-b3402f1df06a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3737292-08a5-423b-b3c3-d1fe66130d41",
   "metadata": {
    "id": "d3737292-08a5-423b-b3c3-d1fe66130d41"
   },
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45915e68-0d12-4653-9476-a91a9f31ca7c",
   "metadata": {
    "id": "45915e68-0d12-4653-9476-a91a9f31ca7c"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92380be3-159e-468b-8373-8ed91baf9da3",
   "metadata": {
    "id": "92380be3-159e-468b-8373-8ed91baf9da3"
   },
   "source": [
    "We'll be using Matplotlib, Tensorflow, and Numpy to create our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5b51d-defe-46c6-8923-ceca3844d308",
   "metadata": {
    "id": "4fb5b51d-defe-46c6-8923-ceca3844d308"
   },
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ae27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will generate 32px square images.\n"
     ]
    }
   ],
   "source": [
    "#Generation resolution factor \n",
    "GENERATE_RES = 1\n",
    "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 10000\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = 'C:/Users/shika/OneDrive/Documents/GitHub/mapGAN/data2'\n",
    "EPOCHS = 250\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "_EzOqD_spCge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EzOqD_spCge",
    "outputId": "ac0f5330-6d18-43c0-b52f-20229ada2232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file: C:/Users/shika/OneDrive/Documents/GitHub/mapGAN/data2\\training_data_32_32.npy\n",
      "Loading previous training pickle...\n"
     ]
    }
   ],
   "source": [
    "training_binary_path = os.path.join(DATA_PATH,\n",
    "        f'training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
    "\n",
    "print(f\"Looking for file: {training_binary_path}\")\n",
    "\n",
    "if not os.path.isfile(training_binary_path):\n",
    "  start = time.time()\n",
    "  print(\"Loading training images...\")\n",
    "\n",
    "  training_data = []\n",
    "  GIS_path = os.path.join(DATA_PATH)\n",
    "  for filename in tqdm(os.listdir(GIS_path)):\n",
    "      path = os.path.join(GIS_path,filename)\n",
    "      image = Image.open(path).resize((GENERATE_SQUARE,\n",
    "            GENERATE_SQUARE),Image.ANTIALIAS)\n",
    "      training_data.append(np.asarray(image))\n",
    "  training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,\n",
    "            GENERATE_SQUARE,IMAGE_CHANNELS))\n",
    "  training_data = training_data.astype(np.float32)\n",
    "  training_data = training_data / 127.5 - 1.\n",
    "\n",
    "  print(\"Saving training image binary...\")\n",
    "  np.save(training_binary_path,training_data)\n",
    "  elapsed = time.time()-start\n",
    "#   print (f'Image preprocess time: {hms_string(elapsed)}')\n",
    "else:\n",
    "  print(\"Loading previous training pickle...\")\n",
    "  training_data = np.load(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "j75fyjPYnaIm",
   "metadata": {
    "id": "j75fyjPYnaIm"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe1cb0-8adf-4350-99ef-3f0ab6bd3223",
   "metadata": {
    "id": "c0fe1cb0-8adf-4350-99ef-3f0ab6bd3223"
   },
   "source": [
    "# 3. Build Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71989c1b-4c64-44a8-9ea5-621e35925d5f",
   "metadata": {
    "id": "71989c1b-4c64-44a8-9ea5-621e35925d5f"
   },
   "source": [
    "## 3.2 Build Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d1b4cb7-c9b8-4b3a-afb7-2953aa4e7524",
   "metadata": {
    "id": "9d1b4cb7-c9b8-4b3a-afb7-2953aa4e7524"
   },
   "outputs": [],
   "source": [
    "4#building the generator\n",
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES>1:\n",
    "      model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "      model.add(BatchNormalization(momentum=0.8))\n",
    "      model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf6f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4096)              40964096  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 8, 256)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 256)        1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 3)         3459      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,445,315\n",
      "Trainable params: 42,444,035\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b61d0-fc84-40e8-938a-5c2aa415c15d",
   "metadata": {
    "id": "f78b61d0-fc84-40e8-938a-5c2aa415c15d"
   },
   "source": [
    "## 3.3 Build Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e3a40e-9662-4e62-b2eb-26a178c9f956",
   "metadata": {
    "id": "78e3a40e-9662-4e62-b2eb-26a178c9f956"
   },
   "outputs": [],
   "source": [
    "#building the discriminator\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CMxsscEFn2rK",
   "metadata": {
    "id": "CMxsscEFn2rK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "guz-TjGHCC82",
   "metadata": {
    "id": "guz-TjGHCC82"
   },
   "outputs": [],
   "source": [
    "def save_images(cnt,noise):\n",
    "  image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "  generated_images = generator.predict(noise)\n",
    "\n",
    "  generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "  image_count = 0\n",
    "  for row in range(PREVIEW_ROWS):\n",
    "      for col in range(PREVIEW_COLS):\n",
    "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "            = generated_images[image_count] * 255\n",
    "        image_count += 1\n",
    "\n",
    "          \n",
    "  output_path = os.path.join(DATA_PATH,'output')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "  \n",
    "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "  im = Image.fromarray(image_array)\n",
    "  im.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cffe1-6cb1-47fa-bc00-8d3d2cd202f0",
   "metadata": {
    "id": "2f6cffe1-6cb1-47fa-bc00-8d3d2cd202f0"
   },
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aQJwWrrVCq95",
   "metadata": {
    "id": "aQJwWrrVCq95"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_generator\u001b[49m(SEED_SIZE, IMAGE_CHANNELS)\n\u001b[0;32m      3\u001b[0m noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m1\u001b[39m, SEED_SIZE])\n\u001b[0;32m      4\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m generator(noise, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_generator' is not defined"
     ]
    }
   ],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])\n",
    "\n",
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "#discriminator loss\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "#generator loss\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a36f25-f9ba-44b9-975f-c0e5a046445d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "21a36f25-f9ba-44b9-975f-c0e5a046445d",
    "outputId": "f768b165-56e9-4b52-dbc5-f77541f909d2"
   },
   "outputs": [],
   "source": [
    "#from https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "#using pre-compiling\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(seed, training=True)\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\\\n",
    "        gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(\\\n",
    "        disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_discriminator, \n",
    "        discriminator.trainable_variables))\n",
    "  return gen_loss,disc_loss\n",
    "\n",
    "#training \n",
    "def train(dataset, epochs):\n",
    "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
    "                                       SEED_SIZE))\n",
    "  start = time.time()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      t = train_step(image_batch)\n",
    "      gen_loss_list.append(t[0])\n",
    "      disc_loss_list.append(t[1])\n",
    "\n",
    "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "    epoch_elapsed = time.time()-epoch_start\n",
    "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "           ' {hms_string(epoch_elapsed)}')\n",
    "    save_images(epoch,fixed_seed)\n",
    "\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Training time: {hms_string(elapsed)}')\n",
    "\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KoJKOmyrDAcF",
   "metadata": {
    "id": "KoJKOmyrDAcF"
   },
   "source": [
    "Optimizing for Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8AVXxHd1C-qB",
   "metadata": {
    "id": "8AVXxHd1C-qB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
